{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4aca9f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25f943",
   "metadata": {},
   "source": [
    "# Homework 1: Causality and Expressions\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, run the previous cell to load the provided tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ccdd15a",
   "metadata": {},
   "source": [
    "**Recommended Readings:**\n",
    "\n",
    "- [What is Data Science?](http://www.inferentialthinking.com/chapters/01/what-is-data-science.html)\n",
    "- [Causality and Experiments](http://www.inferentialthinking.com/chapters/02/causality-and-experiments.html) \n",
    "- [Programming in Python](http://www.inferentialthinking.com/chapters/03/programming-in-python.html)\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is **due Wednesday, 1/25 at 11:00pm PT**. Turn it in by Tuesday, 1/24 at 11:00pm PT for 5 extra credit points. Late work will not be accepted as per the [policies](http://data8.org/sp23/policies/) page.\n",
    "\n",
    "**Note: This homework has hidden tests on it. That means even though tests may say 100% passed, it doesn't mean your final grade will be 100%. We will be running more hidden tests for correctness once everyone turns in the homework.**\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the [policies](http://data8.org/sp23/policies/#academic-honesty) page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. Office hours are held Monday-Friday. The schedule appears on [http://data8.org/sp23/officehours/](http://data8.org/sp23/officehours/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8cfbd3",
   "metadata": {},
   "source": [
    "## 1. Scary Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e7796",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "An ad for ADT Security Systems says,\n",
    "\n",
    "> \"When you go on vacation, burglars go to work [...] According to FBI statistics, over 25% of home burglaries occur between Memorial Day to Labor Day.\"\n",
    "\n",
    "Do the data in the ad support the claim that burglars are more likely to go to work during the time between Memorial Day to Labor Day? Please explain your answer. **(6 Points)**\n",
    "\n",
    "**Note:** You can assume that \"over 25%\" means only slightly over. Had it been much over, say closer to 30%, then the marketers would have said so.\n",
    "\n",
    "**Note:** Memorial Day is observed on the last Monday of May and Labor Day is observed on the first Monday of September.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df539d9",
   "metadata": {},
   "source": [
    "No, because 25% is the same proportion as this period of time in the entire year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9500e4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 2. Characters in Little Women\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acea68",
   "metadata": {},
   "source": [
    "In lecture, we counted the number of times that the literary characters were named in each chapter of the classic book, [*Little Women*](https://inferentialthinking.com/chapters/01/3/1/Literary_Characters.html?highlight=little%20women). In computer science, the word \"character\" also refers to a letter, digit, space, or punctuation mark; any single element of a text. The following code generates a scatter plot in which each dot corresponds to a chapter of *Little Women*. The horizontal position of a dot measures the number of periods in the chapter. The vertical position measures the total number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1104b162",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "\n",
    "# This cell contains code that hasn't yet been covered in the course,\n",
    "# but you should be able to interpret the scatter plot it generates.\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "little_women_url = 'https://www.inferentialthinking.com/data/little_women.txt'\n",
    "chapters = urlopen(little_women_url).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Periods',    np.char.count(chapters, '.'),\n",
    "    'Characters', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0854e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Around how many periods are there in the chapter with the most characters? Assign either 1, 2, 3, 4, or 5 to the name `characters_q1` below. **(4 Points)**\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000\n",
    "\n",
    "\n",
    "**Note:** If you run into a `NameError: name 'grader' is not defined` error in the autograder cell below (and in any assignment), please re-run the first cell at the very top of this notebook!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea00e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_q1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be35118",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_1</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q2_1 results: All test cases passed!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf450dc",
   "metadata": {},
   "source": [
    "The test above checks that your answers are in the correct format. **This test does not check that you answered correctly**, only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad370f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Which of the following chapters has the most characters per period? Assign either 1, 2, or 3 to the name `characters_q2` below. **(4 Points)**\n",
    "\n",
    "1. The chapter with about 60 periods\n",
    "2. The chapter with about 350 periods\n",
    "3. The chapter with about 440 periods\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa152de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80030fbd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_2</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q2_2 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976efa5",
   "metadata": {},
   "source": [
    "Again, the test above checks that your answers are in the correct format, but not that you have answered correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8618d",
   "metadata": {},
   "source": [
    "To discover more interesting facts from this plot, check out [Section 1.3.2](https://inferentialthinking.com/chapters/01/3/2/Another_Kind_Of_Character.html) in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53660c92",
   "metadata": {},
   "source": [
    "## 3. Names and Assignment Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f54b61",
   "metadata": {},
   "source": [
    "**Question 1.** When you run the following cell, Python produces a cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eb6561",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (2912417615.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m4 = 2 + 2\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba08169",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code, and then assign 1, 2, 3, or 4 to `names_q1` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. Python is smart and already knows `4 = 2 + 2`.\n",
    "\n",
    "2. In Python, it's a rule that the `=` sign must have a variable name to its left, and `4` isn't a variable name.\n",
    "\n",
    "3. It should be `2 + 2 = 4`.\n",
    "\n",
    "4. I don't get an error message. This is a trick question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bf609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "540ae31c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_1</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q3_1 results: All test cases passed!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f638e",
   "metadata": {},
   "source": [
    "**Question 2.** When you run the following cell, Python will produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd1eb03",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3853341378.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msix = two plus two\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "two = 3\n",
    "six = two plus two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04711b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, 3, or 4 to `names_q2` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. The `plus` operation only applies to numbers, not the word \"two\".\n",
    "\n",
    "2. The name \"two\" cannot be assigned to the number 3.\n",
    "\n",
    "3. Two plus two is four, not six.\n",
    "\n",
    "4. The name `plus` isn't a built-in operator; instead, addition uses `+`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c2e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6fe080e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_2</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q3_2 results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9c8a0",
   "metadata": {},
   "source": [
    "**Question 3.** Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd5a118",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3 * x\n",
    "x = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30512f4e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What is `y` after running this cell, and why? Choose the best explanation and assign 1, 2, 3, or 4 to `names_q3` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. `y` is equal to 6, because the second `x = 4` has no effect since `x` was already defined.\n",
    "\n",
    "2. `y` is equal to 6, because `x` was 2 when `y` was assigned, and 3 * 2 is 6.\n",
    "\n",
    "3. `y` is equal to 12, because `x` is 4 and 3 * 4 is 12.\n",
    "\n",
    "4. `y` is equal to 12, because assigning `x` to 4 will update `y` to 12 since `y` was defined in terms of `x`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd498eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_q3 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c9f5c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_3</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q3_3 results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505d7d6",
   "metadata": {},
   "source": [
    "## 4. Differences Between Majors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b775ac",
   "metadata": {},
   "source": [
    "Berkeley‚Äôs Office of Planning and Analysis (OPA) provides data on numerous aspects of the campus. Adapted from the OPA website, the table below displays the number of degree recipients in three majors in the 2008-2009 and 2017-2018 academic years.\n",
    "\n",
    "| Major                              | 2008-2009    | 2017-2018   |\n",
    "|------------------------------------|--------------|-------------|\n",
    "| Gender and Women's Studies         |      17      |    28       |\n",
    "| Linguistics                        |      49      |    67       |\n",
    "| Rhetoric                           |      113     |    56       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbe3da",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Suppose you want to find the **biggest** absolute difference between the number of degree recipients in the two years, among the three majors.\n",
    "\n",
    "In the cell below, compute this value and call it `biggest_change`. Use a single expression (a single line of code) to compute the answer. Let Python perform all the arithmetic (like subtracting 49 from 67) rather than simplifying the expression yourself. The built-in `abs` function takes a numerical input and returns the absolute value. The built-in `max` function can take in 3 arguments and returns the maximum of the three numbers. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_1\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b712b981",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_change = max(abs(17-28),abs(49-67),abs(113-56))\n",
    "biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5a973b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_1</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q4_1 results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7293e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Which of the three majors had the **smallest** absolute difference? Assign `smallest_change_major` to 1, 2, or 3 where each number corresponds to the following major:\n",
    "\n",
    "1. Gender and Women's Studies  \n",
    "2. Linguistics  \n",
    "3. Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the smallest absolute difference. **(4 Points)** \n",
    "\n",
    "_Hint:_ You should be able to answer by rough mental arithmetic, without having to calculate the exact value for each major.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_2\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79c95043",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_change_major = 1\n",
    "smallest_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42ec5581",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_2</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q4_2 results: All test cases passed!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de350670",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.**  For each major, define the ‚Äúrelative change‚Äù to be the following: $\\large{\\frac{\\text{absolute difference}}{\\text{value in 2008-2009}} * 100}$ \n",
    "\n",
    "Fill in the code below such that `gws_relative_change`, `linguistics_relative_change` and `rhetoric_relative_change` are assigned to the relative changes for their respective majors. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_3\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 0 \n",
    " - 0\n",
    " - 1\n",
    " - 2\n",
    " - 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2613a067",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64.70588235294117, 36.734693877551024, 101.78571428571428)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gws_relative_change = (abs(17-28) / 17) * 100\n",
    "linguistics_relative_change = (abs(67-49)/49)*100\n",
    "rhetoric_relative_change = (abs(113-56)/56)*100\n",
    "gws_relative_change, linguistics_relative_change, rhetoric_relative_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb5ebca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_3</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q4_3 results: All test cases passed!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c5c06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Assign `biggest_rel_change_major` to 1, 2, or 3 where each number corresponds to to the following: \n",
    "\n",
    "1. Gender and Women's Studies  \n",
    "2. Linguistics  \n",
    "3. Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the biggest relative change. **(4 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_4\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99d8b127",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_rel_change_major = 3\n",
    "biggest_rel_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f75842c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_4</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q4_4 results: All test cases passed!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07361832",
   "metadata": {},
   "source": [
    "## 5. Nearsightedness Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f83b0e",
   "metadata": {},
   "source": [
    "[Myopia](https://en.wikipedia.org/wiki/Myopia), or nearsightedness, results from a number of genetic and environmental factors. In 1999, Quinn et al studied the relation between myopia and ambient lighting at night (for example, from nightlights or room lights) during childhood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4a081",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.** The data were gathered by the following procedure, reported in the study. \"Between January and June 1998, parents of children aged 2-16 years [...] that were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire on the child's light exposure both at present and before the age of 2 years.\" Was this study observational, or was it a controlled experiment? Explain. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382b09d",
   "metadata": {},
   "source": [
    "This is an observational study because there are no controlled variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df7e16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.** The study found that of the children who slept with a room light on before the age of 2, 55% were myopic. Of the children who slept with a night light on before the age of 2, 34% were myopic. Of the children who slept in the dark before the age of 2, 10% were myopic. The study concluded the following: \"The prevalence of myopia [...] during childhood was strongly associated with ambient light exposure during sleep at night in the first two years after birth.\"\n",
    "\n",
    "Do the data support this statement? Why or why not? You may interpret \"strongly\" in any reasonable qualitative way. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db316dfb",
   "metadata": {},
   "source": [
    "Support this claim because no matter which light is turned on, this results in an increase of over 100% in the proportion of people with myopia compared to when it's in darkness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db35e52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.** On May 13, 1999, CNN reported the results of this study under the headline, \"Night light may lead to nearsightedness.\" Does the original study claim that night light causes nearsightedness? **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da214e28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 4.** The final paragraph of the CNN report said that \"several eye specialists\" had pointed out that the study should have accounted for heredity.\n",
    "\n",
    "Myopia is passed down from parents to children. Myopic parents are more likely to have myopic children, and may also be more likely to leave lights on habitually (since the parents have poor vision). In what way does the knowledge of this possible genetic link affect how we interpret the data from the study? Explain. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51453b8b",
   "metadata": {},
   "source": [
    "This is a complex factor. Genetic myopia was mistaken for myopia caused by light exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb4be6",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 6. Studying the Survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59318b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The Reverend Henry Whitehead was skeptical of John Snow‚Äôs conclusion about the Broad Street pump. After the Broad Street cholera epidemic ended, Whitehead set about trying to prove Snow wrong.  (The history of the event is detailed [here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "He realized that Snow had focused his analysis almost entirely on those who had died. Whitehead, therefore, investigated the drinking habits of people in the Broad Street area who had not died in the outbreak.\n",
    "\n",
    "What is the main reason it was important to study this group? Assign either 1, 2, or 3 to the name `survivor_answer` below. **(4 Points)**\n",
    "\n",
    "1. If Whitehead had found that many people had drunk water from the Broad Street pump and not caught cholera, that would have been evidence against Snow's hypothesis.\n",
    "\n",
    "2. Survivors could provide additional information about what else could have caused the cholera, potentially unearthing another cause.\n",
    "\n",
    "3. Through considering the survivors, Whitehead could have identified a cure for cholera.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_1\n",
    "manual: False\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122a5646",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "survivor_answer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4f74172",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6_1</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q6_1 results: All test cases passed!"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4bf53",
   "metadata": {},
   "source": [
    "**Note:** Whitehead ended up finding further proof that the Broad Street pump played a central role in spreading the disease to the people who lived near it. Eventually, he became one of Snow‚Äôs greatest defenders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc6af2",
   "metadata": {},
   "source": [
    "## 7. Policies and Administrivia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca02dfc",
   "metadata": {},
   "source": [
    "This section of the homework is to ensure that you have read over the policies and frequently asked questions for the course. \n",
    "\n",
    "**It's important that you read through this section of the homework very carefully**. If you can get through all of this section and are sure you have all of the correct resources set up, you will be able to focus on the actual material this semester!\n",
    "\n",
    "Reading through the [policies](http://data8.org/sp23/policies/) and the [FAQ](http://data8.org/sp23/faq/) will help you get through this section very easily. It is recommended you do this before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b274432",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** You have a question regarding the grading of your assignments that has not been previously answered on Ed or the FAQ. Who do you contact? Assign `contact` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. The Instructors\n",
    "2. Post on Ed\n",
    "3. Contact your Lab TA\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_1\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ff894",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2417920",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Why are there typically 2 items listed on Gradescope for each homework assignment? Assign `grades` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. There was a mistake in the grading. I should contact someone about this.\n",
    "2. One assignment is for coding questions (which I will submit to), and the other is automatically submitted for me and contains my written work.\n",
    "3. Trick question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_2\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ee8cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a129936",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.** Regrade deadline dates will always be posted on the same Ed post that releases the assignment grades, common mistakes, and solutions. Can you ask for parts of your assignment regraded after the regrade request window has passed? Assign `regrade` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_3\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrade = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f56c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e87d73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Do you have an Gradescope account? Head to [gradescope.com](http://gradescope.com) and check if you see Data 8. If you do not, please send your Lab TA an email with your email and student ID number. \n",
    "\n",
    "Once you have been enrolled, go to the Data 8 Gradescope course website. At the end of the url link, you should see a six-digit number. Assign `gradescope` to that number. **(4 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_4\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradescope = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b0b64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d0945b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.** Given the following scenarios, assign `acceptable` to the corresponding number of the scenario that is permissible given the guidelines on the [policies](http://data8.org/sp23/policies/) page. **(4 Points)**\n",
    "\n",
    "1. Nicole gets stuck on a homework assignment, so she googles a fix. She stumbles across a pdf of the solutions for the homework assignment from a previous semester's offering of Data 8. After inspecting the solution, Nicole writes her own solution and submits the assignment.\n",
    "\n",
    "2. After getting confused by a project, James asks his friend for help. His friend Padma helps by walking James through her own logic, without showing her code, pointing out areas that are important given the context of the question. Upon hearing his friend's logic, James writes his own code and completes the project.\n",
    "\n",
    "3. Ciara (who is in a regular lab) has an extremely busy schedule, so she really wants to leave lab early by finishing it and getting checked off. Her neighbor, Prasann, simply turns his computer so Ciara can see how he completed some questions. After looking at his code, Ciara finishes the lab and gets checked off.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_5\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aef7ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fc1be0b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.** To make sure you have read through the [policies](http://data8.org/sp23/policies/) and the [FAQ](http://data8.org/sp23/faq/) carefully, how many HW and lab drops are there? Assign `drops` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. Two homework drops and three lab drops\n",
    "2. Two homework drops and two lab drops\n",
    "3. Only two homework drops\n",
    "4. One homework drop and two lab drops\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_6\n",
    "points:\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539266d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e76ef1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14554b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7.** Does Data 8 offer alternate final exam to those with class conflicts? Assign `exams` to the number corresponding to the best choice below. **(3 Points)**\n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_7\n",
    "points:\n",
    " - 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104abe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6857d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "450892d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8:** Are you actually checking Ed? Go to this semester's [Data 8 Ed](https://edstem.org/us/courses/34576/discussion/) and find an instructor posted thread with a certain secret phrase. Assign `secret` to this secret phrase in quotes (i.e. as a string). **(4 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_8\n",
    "points:\n",
    " - 0\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a84456",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b96565",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530cb0d",
   "metadata": {},
   "source": [
    "## 8. Welcome Survey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfe2d74b",
   "metadata": {},
   "source": [
    "**Question 1.** Please complete the welcome survey below in order to receive credit for homework 1. **(1 Point)**\n",
    "\n",
    "- Spring 2023 Welcome Survey: [https://forms.gle/TEz7oHmwkG8cvfEK6](https://forms.gle/TEz7oHmwkG8cvfEK6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf72ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `survey` to the secret phrase given at the end of the welcome survey. Make sure the phrase is in quotes (i.e. is a string)!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_1\n",
    "points:\n",
    " - 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cdabb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ed341f",
   "metadata": {},
   "source": [
    "You're done with Homework 1!  \n",
    "\n",
    "**Important submission information:** Be sure to run the tests and verify that they all pass, then choose **Save Notebook** from the **File** menu, then **run the final cell** and click the link to download the zip file. Then, go to [Gradescope](https://www.gradescope.com/courses/489304) and submit the zip file to the corresponding assignment. The name of this assignment is \"HW 01 Autograder\". **It is your responsibility to make sure your work is saved before running the last cell.**\n",
    "\n",
    "Once you have submitted, your Gradescope assignment should look something like the following image if you have passed all tests.\n",
    "\n",
    "**Note:** *This is a photo of a generic Gradescope submission result, and it does not included the same test numbers as this assignment. Please check that all test cases have passed for each question.*\n",
    "\n",
    "<img src=\"gradescope.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62ea8d87",
   "metadata": {},
   "source": [
    "## Pets of Data 8\n",
    "\n",
    "Here is a dog photo for your enjoyment :) Congrats on finishing homework 1!\n",
    "\n",
    "<img src=\"./zoey.jpeg\" width=\"30%\" alt=\"Close up of a dog at the beach\"/>\n",
    "\n",
    "Dog of the week: **Zoey**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4db4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c314e4dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2_1 results: All test cases passed!\n",
       "\n",
       "q2_2 results: All test cases passed!\n",
       "\n",
       "q3_1 results: All test cases passed!\n",
       "\n",
       "q3_2 results: All test cases passed!\n",
       "\n",
       "q3_3 results: All test cases passed!\n",
       "\n",
       "q4_1 results: All test cases passed!\n",
       "\n",
       "q4_2 results: All test cases passed!\n",
       "\n",
       "q4_3 results: All test cases passed!\n",
       "\n",
       "q4_4 results: All test cases passed!\n",
       "\n",
       "q6_1 results: All test cases passed!\n",
       "\n",
       "q7_1 results:\n",
       "    q7_1 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            contact == 3\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_1 0\n",
       "        Failed example:\n",
       "            contact == 3\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_1 0[0]>\", line 1, in <module>\n",
       "                contact == 3\n",
       "                ^^^^^^^\n",
       "            NameError: name 'contact' is not defined\n",
       "\n",
       "q7_2 results:\n",
       "    q7_2 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            grades == 2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_2 0\n",
       "        Failed example:\n",
       "            grades == 2\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_2 0[0]>\", line 1, in <module>\n",
       "                grades == 2\n",
       "                ^^^^^^\n",
       "            NameError: name 'grades' is not defined\n",
       "\n",
       "q7_3 results:\n",
       "    q7_3 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            regrade == 2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_3 0\n",
       "        Failed example:\n",
       "            regrade == 2\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_3 0[0]>\", line 1, in <module>\n",
       "                regrade == 2\n",
       "                ^^^^^^^\n",
       "            NameError: name 'regrade' is not defined\n",
       "\n",
       "q7_4 results:\n",
       "    q7_4 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            gradescope == 489304\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_4 0\n",
       "        Failed example:\n",
       "            gradescope == 489304\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_4 0[0]>\", line 1, in <module>\n",
       "                gradescope == 489304\n",
       "                ^^^^^^^^^^\n",
       "            NameError: name 'gradescope' is not defined\n",
       "\n",
       "q7_5 results:\n",
       "    q7_5 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            acceptable == 2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_5 0\n",
       "        Failed example:\n",
       "            acceptable == 2\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_5 0[0]>\", line 1, in <module>\n",
       "                acceptable == 2\n",
       "                ^^^^^^^^^^\n",
       "            NameError: name 'acceptable' is not defined\n",
       "\n",
       "q7_6 results:\n",
       "    q7_6 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            drops == 2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_6 0\n",
       "        Failed example:\n",
       "            drops == 2\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_6 0[0]>\", line 1, in <module>\n",
       "                drops == 2\n",
       "                ^^^^^\n",
       "            NameError: name 'drops' is not defined\n",
       "\n",
       "q7_7 results:\n",
       "    q7_7 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            exams == 1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_7 0\n",
       "        Failed example:\n",
       "            exams == 1\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_7 0[0]>\", line 1, in <module>\n",
       "                exams == 1\n",
       "                ^^^^^\n",
       "            NameError: name 'exams' is not defined\n",
       "\n",
       "q7_8 results:\n",
       "    q7_8 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            type(secret) == str\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q7_8 0\n",
       "        Failed example:\n",
       "            type(secret) == str\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_8 0[0]>\", line 1, in <module>\n",
       "                type(secret) == str\n",
       "                     ^^^^^^\n",
       "            NameError: name 'secret' is not defined\n",
       "\n",
       "    q7_8 - 2 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            len(secret)\n",
       "        Expecting:\n",
       "            8\n",
       "        **********************************************************************\n",
       "        Line 1, in q7_8 1\n",
       "        Failed example:\n",
       "            len(secret)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q7_8 1[0]>\", line 1, in <module>\n",
       "                len(secret)\n",
       "                    ^^^^^^\n",
       "            NameError: name 'secret' is not defined\n",
       "\n",
       "q8_1 results:\n",
       "    q8_1 - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            survey == \"data8 is data gr8\"\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q8_1 0\n",
       "        Failed example:\n",
       "            survey == \"data8 is data gr8\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/home/boluopai/miniforge3/envs/dm_env/lib/python3.11/doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q8_1 0[0]>\", line 1, in <module>\n",
       "                survey == \"data8 is data gr8\"\n",
       "                ^^^^^^\n",
       "            NameError: name 'survey' is not defined"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfc2d6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdeeb65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7208310",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
